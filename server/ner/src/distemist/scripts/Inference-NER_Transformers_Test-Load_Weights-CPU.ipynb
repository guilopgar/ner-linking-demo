{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bsc-bio-ehr-es\"\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 74\n",
    "SEQ_LEN = 128\n",
    "LR = 3e-5\n",
    "N_EXEC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_utils_path = [\"../../\", \"../../../\"]\n",
    "model_root_path = \"../../models/\"\n",
    "corpus_path = \"../datasets/distemist/\"\n",
    "ss_corpus_path = corpus_path + \"distemist-SSplit-text/\"\n",
    "subtask_path = \"subtrack1_entities/distemist_subtrack1_training_mentions.tsv\"\n",
    "codes_path = corpus_path + \"dictionary_distemist.tsv\"\n",
    "RES_DIR = \"./preds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(RES_DIR):\n",
    "    os.makedirs(RES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 09:22:20.189098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, XLMRobertaTokenizerFast, RobertaTokenizerFast\n",
    "\n",
    "# All variables that depend on model_name\n",
    "if MODEL_NAME == 'beto':\n",
    "    model_path = model_root_path + \"BERT/pytorch/BETO/\"\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'beto_galen':\n",
    "    model_path = model_root_path + \"BERT/pytorch/BETO-Galen/\"\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'mbert':\n",
    "    model_path = model_root_path + \"BERT/pytorch/mBERT/\"\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'mbert_galen':\n",
    "    model_path = model_root_path + \"BERT/pytorch/mBERT-Galen/\"\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'xlmr':\n",
    "    model_path = model_root_path + \"XLM-R/pytorch/xlm-roberta-base/\"\n",
    "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "\n",
    "elif MODEL_NAME == 'xlmr_large':\n",
    "    model_path = model_root_path + \"XLM-R/pytorch/xlm-roberta-large/\"\n",
    "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'xlmr_galen':\n",
    "    model_path = model_root_path + \"XLM-R/pytorch/XLM-R-Galen/\"\n",
    "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'bsc-bio-ehr-es':\n",
    "    model_path = model_root_path + \"RoBERTa/pytorch/\" + MODEL_NAME\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "\n",
    "elif MODEL_NAME == 'roberta-base-bne':\n",
    "    model_path = model_root_path + \"RoBERTa/pytorch/\" + MODEL_NAME\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "elif MODEL_NAME == 'roberta-large-bne':\n",
    "    model_path = model_root_path + \"RoBERTa/pytorch/\" + MODEL_NAME\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(model_path, do_lower_case=False)\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: NO AVAILABLE MODEL!!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Auxiliary components\n",
    "import sys\n",
    "for utils_path in arr_utils_path:\n",
    "    sys.path.insert(0, utils_path)\n",
    "\n",
    "import utils.ner.load_data as load_data\n",
    "import utils.ner.pre_process as pre_proc\n",
    "import utils.ner.post_process as post_proc\n",
    "import utils.tf.loss as tf_loss\n",
    "import src.distemist.utils.metrics as metrics\n",
    "\n",
    "# Hyper-parameters\n",
    "text_col = \"raw_text\"\n",
    "GREEDY = True\n",
    "IGNORE_VALUE = -100\n",
    "LOGITS = False\n",
    "ROUND_N = 4\n",
    "\n",
    "custom_tokenizer = pre_proc.TransformersTokenizer(\n",
    "    tokenizer=tokenizer, ign_value=IGNORE_VALUE\n",
    ")\n",
    "\n",
    "# IOB labels\n",
    "B_VAL, I_VAL, EMPTY_VAL = \"B\", \"I\", \"O\"\n",
    "ALLOW_IN_AS_BEGIN = False\n",
    "\n",
    "custom_tokenizer = pre_proc.TransformersTokenizer(\n",
    "    tokenizer=tokenizer, ign_value=IGNORE_VALUE\n",
    ")\n",
    "\n",
    "random_seed = 0\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "JOB_NAME = JOB_NAME = \"distemist_ner-\" + MODEL_NAME + \"-bs_\" + str(BATCH_SIZE) + \\\n",
    "    \"-seq_len_\" + str(SEQ_LEN) + \"-lr_\" + str(LR) + \"-epoch_\" + str(EPOCHS) + \\\n",
    "    \"_exec_\" + str(N_EXEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = corpus_path + \"test_annotated/text_files/\"\n",
    "test_files = [f for f in os.listdir(test_path) if os.path.isfile(test_path + f) and f.split('.')[-1] == \"txt\"]\n",
    "test_data = load_data.load_text_files(test_files, test_path)\n",
    "df_text_test = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in test_files], 'raw_text': test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data pre-processing\n",
    "\n",
    "We generate the valid inputs tot he model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoders as dict (more computationally efficient)\n",
    "lab_encoder = {B_VAL: 0, I_VAL: 1, EMPTY_VAL: 2}\n",
    "lab_decoder = {0: B_VAL, 1: I_VAL, 2: EMPTY_VAL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the custom pre-processing objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_annotator = pre_proc.AnnotatorContinuous(\n",
    "    labeler=pre_proc.LabelerIOB(\n",
    "        empty_val=EMPTY_VAL,\n",
    "        begin_val=B_VAL,\n",
    "        inside_val=I_VAL\n",
    "    )\n",
    ")\n",
    "\n",
    "sub_lab_converter = pre_proc.AllSubLabel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_list = sorted(set(df_text_test[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test documents: 250\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of documents:\", len(test_doc_list), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_sub_corpus_path = ss_corpus_path + \"test/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_test = load_data.load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = pd.DataFrame({\n",
    "    \"doc_id\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tok_dict, test_y, test_frag, test_start_end_frag, \\\n",
    "                test_word_id = pre_proc.create_input_data(df_text=df_text_test, text_col=text_col, \n",
    "                                    df_ann=df_empty,\n",
    "                                    arr_doc=test_doc_list, ss_dict=ss_dict_test,\n",
    "                                    tokenizer=custom_tokenizer, \n",
    "                                    arr_lab_encoder=[lab_encoder], \n",
    "                                    seq_len=SEQ_LEN,\n",
    "                                    annotator=custom_annotator,\n",
    "                                    sub_lab_converter=sub_lab_converter,\n",
    "                                    greedy=GREEDY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Exec time of pre-processing test documents (in mins): 0.09127397537231445\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Exec time of pre-processing documents (in mins):\", (end_time - start_time) / 60, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind, test_att = test_tok_dict['input_ids'], test_tok_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 09:22:26.907408: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-12 09:22:26.976665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.976920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:26.976967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.977191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:26.977234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.977456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:61:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:26.977497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.977719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:62:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:26.977732: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-07-12 09:22:26.982505: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-07-12 09:22:26.982538: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-07-12 09:22:26.983424: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-12 09:22:26.984142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-12 09:22:26.984599: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-07-12 09:22:26.985386: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-07-12 09:22:26.985480: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-07-12 09:22:26.985551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.985834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.986092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.986352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.986607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.986863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.987115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.987365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:26.987585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-07-12 09:22:26.987905: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-12 09:22:28.847361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.847615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:28.847659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.847879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:28.847922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.848140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:61:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:28.848180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.848398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:62:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-07-12 09:22:28.848441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.848687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.848933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.849178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.849425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.849677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.849924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.850171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:28.850392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-07-12 09:22:28.850438: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-07-12 09:22:35.587831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-12 09:22:35.587861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 \n",
      "2023-07-12 09:22:35.587866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N N N \n",
      "2023-07-12 09:22:35.587869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N N N \n",
      "2023-07-12 09:22:35.587872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   N N N N \n",
      "2023-07-12 09:22:35.587874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   N N N N \n",
      "2023-07-12 09:22:35.588121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.588429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.588701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.588970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.589226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.589485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.589735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.589985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.590236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.590480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 18676 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6)\n",
      "2023-07-12 09:22:35.590760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.590989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22317 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:42:00.0, compute capability: 8.6)\n",
      "2023-07-12 09:22:35.591166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.591395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 16753 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6)\n",
      "2023-07-12 09:22:35.591568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-12 09:22:35.591796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 9254 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:62:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 09:22:36.486211: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-07-12 09:22:36.909771: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-07-12 09:22:36.909824: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForTokenClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForTokenClassification, TFXLMRobertaForTokenClassification, TFRobertaForTokenClassification \n",
    "\n",
    "if MODEL_NAME.split('_')[0] in ('beto', 'mbert'):\n",
    "    model = TFBertForTokenClassification.from_pretrained(model_path, from_pt=True)\n",
    "    \n",
    "elif MODEL_NAME.split('_')[0] == 'xlmr':\n",
    "    model = TFXLMRobertaForTokenClassification.from_pretrained(model_path, from_pt=True)\n",
    "\n",
    "elif MODEL_NAME in ('bsc-bio-ehr-es', 'roberta-base-bne', 'roberta-large-bne'):\n",
    "    model = TFRobertaForTokenClassification.from_pretrained(model_path, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/guillermo/miniconda3/envs/tf25_picasso/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5044: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "iob_num_labels = len(lab_encoder)\n",
    "\n",
    "input_ids = Input(shape=(SEQ_LEN,), name='input_ids', dtype='int64')\n",
    "attention_mask = Input(shape=(SEQ_LEN,), name='attention_mask', dtype='int64')\n",
    "\n",
    "out_seq = model.layers[0](input_ids=input_ids, attention_mask=attention_mask)[0] # take the output sub-token sequence \n",
    "\n",
    "# IOB-2\n",
    "out_iob = Dense(units=iob_num_labels, kernel_initializer=GlorotUniform(seed=random_seed))(out_seq) # Multi-class classification \n",
    "out_iob_model = Activation(activation='softmax', name='iob_output')(out_iob)\n",
    "\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=out_iob_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roberta (TFRobertaMainLayer)    TFBaseModelOutputWit 124052736   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 3)       2307        roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "iob_output (Activation)         (None, 128, 3)       0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 124,055,043\n",
      "Trainable params: 124,055,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2c2054ddc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "optimizer = tfa.optimizers.RectifiedAdam(learning_rate=LR)\n",
    "loss = {'iob_output': tf_loss.TokenClassificationLoss(\n",
    "    from_logits=LOGITS, ignore_val=IGNORE_VALUE\n",
    ")}\n",
    "loss_weights = {'iob_output': 1}\n",
    "model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights)\n",
    "\n",
    "# Load model weights\n",
    "model.load_weights('../models/model_checkpoints/' + JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 09:22:43.027630: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-07-12 09:22:43.050434: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3892755000 Hz\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict({'input_ids': test_ind, 'attention_mask': test_att})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Exec time of making predictions (in mins): 0.09016862710316977\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Exec time of making predictions (in mins):\", (end_time - start_time) / 60, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data post-processing\n",
    "\n",
    "We post-process the models predictions to generate valid annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the custom post-processing objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_preds_converter = post_proc.ProdWordPreds()\n",
    "\n",
    "custom_ann_extractor = post_proc.AnnExtractorContinuous(\n",
    "    lab_extractor=post_proc.LabExtractorIOB(\n",
    "        arr_lab_decoder=[lab_decoder],\n",
    "        empty_val=EMPTY_VAL,\n",
    "        begin_val=B_VAL,\n",
    "        inside_val=I_VAL\n",
    "    ), \n",
    "    allow_inside_as_begin=ALLOW_IN_AS_BEGIN\n",
    ")\n",
    "\n",
    "custom_preds_frag_tok = post_proc.NeuralPredsFragTok(\n",
    "    tokenizer=custom_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_codes = set(map(lambda k: k.split('\\t')[0], open(codes_path).readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = post_proc.extract_annotations_from_model_preds(arr_doc=test_doc_list, arr_frags=test_frag,\n",
    "                                      arr_preds=[test_preds],\n",
    "                                      arr_start_end=test_start_end_frag, arr_word_id=test_word_id,\n",
    "                                      arr_preds_pos_tok=custom_preds_frag_tok.calculate_pos_tok(\n",
    "                                          arr_len=test_start_end_frag\n",
    "                                      ),\n",
    "                                      ann_extractor=custom_ann_extractor,\n",
    "                                      word_preds_converter=word_preds_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = metrics.format_distemist_preds(\n",
    "    df_preds=df_pred_test,\n",
    "    df_text=df_text_test,\n",
    "    text_col=text_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to file headers, you are on subtask ner, predictions file\n"
     ]
    }
   ],
   "source": [
    "df_pred_test = metrics.format_distemist_df(df=df_pred_test, valid_codes=valid_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preds\n",
    "df_pred_test.to_csv(\n",
    "    RES_DIR + \"df_pred_test.tsv\", header=True, index=False, sep='\\t'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. Exec time of post-processing predictions (in mins):\", (end_time - start_time) / 60, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to file headers, you are on subtask ner, GS file\n"
     ]
    }
   ],
   "source": [
    "df_test_gs = metrics.format_distemist_df(\n",
    "    df=pd.read_csv(\n",
    "        corpus_path + \"test_annotated/\" + subtask_path.replace('training', 'test'), \n",
    "        header=0, sep=\"\\t\"\n",
    "    ),\n",
    "    valid_codes=valid_codes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, f1 = metrics.calculate_distemist_metrics(gs=df_test_gs, pred=df_pred_test, subtask=subtask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-avg P = 0.8049 | micro-avg R = 0.764 | micro-avg F1 = 0.784\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nmicro-avg P = \", round(p, ROUND_N), \" | micro-avg R = \", round(r, ROUND_N), \n",
    "      \" | micro-avg F1 = \", round(f1, ROUND_N), \"\\n\", sep=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
